{"podcast_details": {"podcast_title": "The AI Breakdown: Daily Artificial Intelligence News and Discussions", "episode_title": "Was Nvidia's Earnings Call A '1995 Internet Moment'?", "episode_image": "https://megaphone.imgix.net/podcasts/9ad36894-20f2-11ee-9d6c-d76aa9b66d23/image/BITCOIN_BUILDERS_3.png?ixlib=rails-4.3.1&max-w=3000&max-h=3000&fit=crop&auto=format,compress", "episode_transcript": " Today on the AI Breakdown, we're discussing why one prominent Wall Street analyst called Nvidia's earnings call yesterday a 1995 internet moment. Before that on the brief, an incredible story of AI helping a paralyzed woman speak for the first time in 18 years. The AI Breakdown is a daily podcast and video about the most important news and discussions in AI. Go to breakdown.network for more information about our YouTube, our Discord, and our newsletter. Welcome back to the AI Breakdown Brief, all the AI headline news you need in around 5 minutes. Whenever politicians do their normal, there's great opportunity as well as great challenge. When it comes to AI, one of the things that they speak about in that opportunity side is the potential for incredible advancements in health and medicine. Today, the New York Times tells the story of exactly one of those types of advancements. In this instance, AI has helped a woman who lost the ability to speak about 18 years ago actually communicate with the world again just through her thoughts. In 2005, at the age of 30, Ann Johnson suffered a debilitating paralyzing stroke. She's been part of an experimental procedure now in which researchers have implanted a device in her brain that can detect brain signals from speech-related sensory and motor processes that are linked to the mouth, lips, jaw, tongue, and larynx. What's different about this particular approach tried on Ann Johnson is that instead of training the AI to recognize individual words, instead they're training it to recognize phonemes or sound units such as OU and AH that are the building blocks of any word. Product manager David Moses said it's like an alphabet of speech sounds. Using the system, Ann can communicate 78 words per minute. That's a huge advancement over similar attempts at previous approaches that have produced 15 to 18 words a minute, but still around half the typical conversational speech of around 160 words per minute. Now the other interesting piece about this is that in addition to translating just the brain signals for these sounds or phonemes, they also worked with another company to translate the brain signals around specific emotions. Thus when she was speaking, she could also register muscle movement for sad, happy, excited, and that translates not only into a waveform of the speech which produces sound, but also into a digital avatar which mirrors her emotions visually as well. Now the approach isn't perfect as you would expect. It gets about 75% of the words completely correct, and on any given sentence about half of them translate all the words in the sentence correctly. But that's obviously still a huge improvement over not being able to communicate at all. What's more, this is a field that is rapidly evolving, and many researchers believe that there will be commercially available devices of this type that are approved for medical use within the decade. Moving next to the very opposite end of the spectrum in a very contentious area of artificial intelligence, if everyone had questions around how legal precedent matters, the decision handed down earlier this week confirming that AI-produced work could not be copyrighted is already having an impact on the strikes in Hollywood. The TLDR is that in a world where AI-produced material can't be copyrighted, then studios can't just rely on AI, because basically anything they produce would be immediately in the public domain, which would make it much harder for them to capture the value of that material. At least right now, legal precedent says that humans have to have a significant role in the production of a creative material for it to be copyrighted, and so that creates some amount of a template in which the studios have to commit to their being human leadership of projects in a continued and ongoing way, because otherwise the things that they produce won't be protected. Now, of course, there is still a ton of gray area in terms of how much human involvement is needed for something to be copyrighted, and many, many lawyers will likely get rich trying to solve exactly that question, but at least it's making clear that any sort of complete one-to-one switch from human to AI just isn't viable. At the same time, stories of studios offering expensive AI roles continue to make news. The latest from CNBC, film and TV studios post AI jobs with salaries up to $1 million as workers strike. We talked about Netflix's $900,000 AI machine learning position just a couple weeks ago, and it seems like every couple days there's another one of these stories. This is once again one of those things that is interesting from a meta-narrative perspective. Not so much that there are these jobs that exist, but that their existence is seen as newsworthy by major publications. In some ways, these big splashy numbers serve to drive AI into a larger subsection of the culture war, which is frankly a little bit closer to a class war. Staying on the theme of capitalism and consumerism, we are, believe it or not, coming up on holiday sales season. And despite the stock market rallying thanks largely to NVIDIA, the broader economy is still hurting. Retailers aren't expecting huge growth in sales, and for that reason, they are looking to AI to help drive more efficiencies and better targeting. As Forbes writes, due to the sales slowdown Salesforce reported, retailers increasingly are turning to AI to reduce costs and drive sales. AI-driven product recommendations are expected to impact $194 billion in online sales in November and December. This may be a somewhat less interesting area of artificial intelligence than helping a stroke patient speak again after 18 years of silence, but driving almost $200 billion in sales certainly puts a fine point on just how valuable this technology might be. Lastly, we close on a little bit of commentary from Stephen King after learning that his books were used to train AI. He wrote a short piece for The Atlantic in which he reflected on the state of things. The central question of his piece is can a machine that reads learn to write? And more specifically, is whether you can get a sum that's greater than the parts when you pour it back out. So far, King says the answer is no. At least he says not yet. Quote, creativity can't happen without sentience, and there are now arguments that some AIs are indeed sentient. If that is true now or in the future, then creativity might be possible. I view this possibility with a certain dreadful fascination. Does it make me nervous? Do I feel my territory encroached upon? Not yet, probably because I've reached a fairly advanced age. But he says, I will tell you that this subject always makes me think of that most prescient novel Colossus by D.F. Jones. In it, the world-spanning computer does become sentient and tells its creator, Forbin, that in time, humanity will come to love and respect it. Forbin cries never, but the narrator has the last word and a single word is all it takes. Never? That's going to do it for today's AI Breakdown Brief. If you're enjoying this, please like, subscribe and share it, and I'll be back soon with the main AI breakdown. Welcome back to the AI breakdown. Today we are talking about NVIDIA's earnings report. And just to give a sense of how much more significant the market is treating this than just the earnings report of one company in one quarter, let's look at this tweet from noted Wall Street analyst Dan Ives. He writes, We view last night as a historical moment for the broader tech sector and a sneak preview of what is on the horizon after hearing the guidance heard around the world from the godfather of AI Jensen and NVIDIA, a 1995 internet moment on the doorstep for the tech sector. These are some big bombastic terms. And while of course it's worth being skeptical any time you hear people start comparing things to major previous events, Dan is far from the only person who feels like that's where we are when it comes to artificial intelligence. Now before we get into the earnings report, let's talk about what else has been going on in markets this year. First of all, we've had a historically fast rate hiking cycle from the Federal Reserve. In the wake of being caught out for not moving fast enough on inflation, the Fed wrenched rates from the zero interest rate policies of the entire teens decade up over 500 basis points over the course of about 18 months. Now that has had major impacts on numerous sectors across the economy. One of the consequences of that fastest rate hiking cycle in history was the banking crisis. Numerous banks in the US found themselves with a duration mismatch in which the value of their assets, which were long dated, was lower than the value of their deposits, which people were increasingly pulling out for a variety of reasons, including in some cases challenges in specific industries like crypto and tech, but in other cases just because they could move their money into money market funds and be yielding more. Banks had to sell their long dated bonds for below their value, thus creating a vicious spiral that eventually led to the collapse of banks like Silicon Valley Bank. Okay, so we now have a fast fed rate hiking cycle, we have a banking crisis, and now on top of that we've got outright deflation in China. China has been a drag on the global economy for a number of years now as the zero covid policies in that country created sustained impairment of supply chains and problems with global economic networks, and with deteriorating economic fundamentals people are worried that the problems in China are going to spill over to other parts of the world as well. And yet throughout all of that, this is what the chart of the S&P 500 looks like for this year. Year to date it's up 15.45%. And if you want to know why, look no farther than this man, Jensen Huang. NVIDIA has been the absolute darling and all-star, representing the larger excitement around artificial intelligence following the launch of ChatGPT last November. And there has been a lot that's remarkable about NVIDIA. Here are just a few of the numbers from the earnings report shared yesterday. Net income for last quarter was $6.7 billion, that's a 422% increase from quarter 2 last year. 171% sales growth on an annualized basis to $13.51 billion. Gross margin expanded by 25 percentage points to 71.2% compared to Q2 of last year. Quarter 3 sales guidance of $16 billion, which is a further 18% quarter over quarter growth or 93% annualized. And importantly, when it comes to Wall Street, it's not just about how a company performs, it's about whether it beats expectations or not. NVIDIA had incredibly high expectations coming into this, and it still blew them out of the water. Analysts had estimated $2.07 of profit per share. NVIDIA hit $2.70 per share. Analysts had estimated $11 billion in sales. NVIDIA hit $13.51 billion. Now one of the big drivers was data center sales. Ben Gilbert tweets, I am literally speechless. NVIDIA just grew data center sales 141% in a quarter. That's not compared against this quarter last year. That's literally growth in three months, $4.3 billion to $10.3 billion. That's with the constraint of needing to ship physical hardware to customers. Nuts. So half of NVIDIA's data center revenue comes from cloud providers. Growth in data center revenue from delivery of compute was up 195% during the quarter. And just for some reference, Meta expects to spend $30 billion this year on data centers, while Microsoft reported a record $8.9 billion in capital expenditure last quarter. CEO Jensen Huang leaned into this in the earnings call. He said a new computing era has begun and said we're not shipping close to demand. Now one of the interesting things that's happening now is that everyone is trying to figure out just how NVIDIA got to this point where it's such a dominant player in the space. The New York Times just wrote a piece called How NVIDIA Built a Competitive Moat Around AI Chips and effectively it argues that there's really two parts to the success. The first part was being early. NVIDIA has been at the forefront of innovation in chips for effectively the last 30 years. And that means that they saw AI coming a lot earlier than most others did. As the Times writes, NVIDIA gained a reputation for consistently delivering faster chips every couple of years. In 2017, it started tweaking GPUs to handle specific AI calculations. The second piece is that NVIDIA didn't just sell chips off the shelf. It sold entire systems that could get customers up and running. The Times continues, That same year, 2017, NVIDIA, which typically sold chips or circuit boards for other companies' systems, also began selling complete computers to carry out AI tasks more efficiently. Some of its systems are now the size of supercomputers which it assembles and operates using proprietary networking technology and thousands of GPUs. Said CEO Huang, This type of computing doesn't allow for you to just build a chip and customers use it. You've got to build the whole data center. Now a third piece of their success, which is more recent, is that NVIDIA has been very actively investing. Again from the Times, To further extend its influence, NVIDIA has also recently forged partnerships with big tech companies and invested in high-profile AI startups that use its chips. One was Inflection AI, which in June announced $1.3 billion in funding from NVIDIA and others. The money was used to help finance the purchase of 22,000 H100 chips. Mustafa Suleyman, Inflection's chief executive, said that there was no obligation to use NVIDIA's products but that competitors offered no viable alternative. None of them came close, he said. Now having NVIDIA as this huge leader comes with downsides as well. As the Times points out, given the demand for its chips, NVIDIA must decide who gets how many of them. That power makes some tech executives uneasy. Clement DeLang, the chief executive of Hugging Face, said, It's really important that hardware doesn't become a bottleneck for AI or a gatekeeper for AI. All in all, this is an interesting countervailing moment to the popular narrative of AI hype ebbing. It may be the case that consumers are using chat GPT slightly less than they were a couple months ago and that we've grown a little tired of the constant another crazy week in AI posts from influencers. But what's also clear is that companies are going all in on this technology, that they see it as fundamentally shifting the paradigm in which they operate and view the need for compute as an existential challenge to be solved. So even if Dan Ives isn't quite correct, if his tweet declaring this the guidance heard around the world in a 1995 internet moment ultimately seems a bit hyperbolic, it is certainly the case that last night's earnings call was not just another earnings call by any stretch of the imagination. Anyways, guys, that is going to do it for today's AI breakdown. If you enjoyed this, send it to your one stock friend, especially that one who's been skeptical of AI. I'd love to recruit them to the AI breakdown community. Thanks as always for listening or watching. Until next time, peace."}, "podcast_summary": "In this podcast transcript, several topics related to AI are discussed. Firstly, an incredible story is shared about AI helping a paralyzed woman communicate with the world again after 18 years of being unable to speak. Through an experimental procedure, a device implanted in her brain detects brain signals related to speech, allowing her to communicate using phonemes or sound units. While the system is not perfect, it represents a huge advancement in assisting individuals with speech impairments, and researchers believe commercially available devices of this type could be approved for medical use within the decade.\n\nNext, the transcript highlights a recent legal precedent stating that AI-produced work cannot be copyrighted. This ruling impacts studios in the entertainment industry, as they cannot solely rely on AI to create material that can be protected. As a result, human involvement and leadership are necessary for creative projects to be copyrighted. Despite this, studios are offering high-paying AI roles, reflecting the growing importance of AI in the industry.\n\nFurthermore, retailers are turning to AI to drive efficiencies and improve targeting during the upcoming holiday sales season. AI-driven product recommendations are projected to impact $194 billion in online sales during November and December. This further emphasizes the value of AI technology in the realm of consumerism and capitalism.\n\nFinally, author Stephen King reflects on the potential of AI to learn to write and whether it can surpass human creativity. While he believes creativity requires sentience, he acknowledges the possibility that some AIs may achieve sentience in the future, which could open the door to AI-generated creativity. The podcast concludes by discussing NVIDIA's recent earnings report, which has been seen as a significant moment for the broader tech sector and an indication of the transformative potential of AI. NVIDIA's impressive growth and dominance in AI chip technology contribute to the excitement surrounding the company and the industry as a whole.", "podcast_guest": {"guest_name": "Jensen Huang", "summary": "Jen-Hsun \"Jensen\" Huang (Chinese: \u9ec3\u4ec1\u52f3; pinyin: Hu\u00e1ng R\u00e9nx\u016bn; Pe\u030dh-\u014de-j\u012b: N\u0302g J\u00een-hun; born February 17, 1963) is a Taiwanese-born American billionaire businessman, electrical engineer, and the co-founder, president and CEO of Nvidia Corporation.\n\n"}, "podcast_highlights": "In this podcast episode, the host discusses key highlights in the field of AI. One highlight is an incredible story of how AI has helped a paralyzed woman communicate by detecting brain signals related to speech. The AI system is trained to recognize phonemes and can currently communicate at a speed of 78 words per minute. Another highlight is the legal precedent that AI-produced work cannot be copyrighted, which impacts the entertainment industry. Despite this, studios continue to offer expensive AI roles. The episode also mentions how retailers are using AI to drive sales during the upcoming holiday season, with AI-driven product recommendations expected to impact $194 billion in online sales. Lastly, the podcast touches on NVIDIA's earnings report, which has been considered a significant moment for the tech sector and the future of AI. The company's success can be attributed to their early investment in AI chips and their ability to offer complete systems for AI tasks."}